{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook to create .json files describing each subject's data set. This is read by the bidsify.py script which then copies all relevant Nifti files to the 'sourcedata' folder, renaming them to adhere to the BIDS guidelines. bidsify.py can be run on Oscar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, glob, os, scipy, json, gzip, shutil, pydicom\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this notebook on your own computer, make sure to first mount Oscar to your finder/explorer. See: https://docs.ccv.brown.edu/oscar/connecting-to-oscar/cifs. In my case, I have mounted the Oscar 'data' drive to /Volumes (on Mac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base dir:\n",
      "/Volumes/data/ofeldman/jvanbaar/polarization/\n",
      "Getting niftis from:\n",
      "/Volumes/data/ofeldman/jvanbaar/polarization/dicomconvert \n",
      " Writing to:\n",
      "/Volumes/data/ofeldman/jvanbaar/polarization/sourcedata\n"
     ]
    }
   ],
   "source": [
    "a = !pwd\n",
    "base_dir = '/Volumes/data/ofeldman/jvanbaar/polarization/'\n",
    "print('Base dir:\\n%s'%base_dir)\n",
    "dataset_dir = base_dir + 'sourcedata'\n",
    "nifti_dir = base_dir + 'dicomconvert'\n",
    "print('Getting niftis from:\\n%s'%nifti_dir , '\\n', 'Writing to:\\n%s'%dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset parameters - change per subject!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bidsify.py will need these details in order to locate the right files. Obviously need to be updated for each task / multi-session study etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = dict()\n",
    "\n",
    "dataset_params[1] = {'ses':1, 'anat_run':9,\n",
    "                     'func_run':{'wordReading':[6,7,8,10,11,12], 'videoWatching':[14,15,16]},\n",
    "                    'anat_sequence':'t1_mprage', 'func_sequence':'SMS_mb3_3mm_TR1500',\n",
    "                    'date':'20190422', 'TR':1.5}\n",
    "dataset_params[2] = {'ses':1, 'anat_run':9,\n",
    "                     'func_run':{'wordReading':[6,7,8,10,11,12], 'videoWatching':[14,15,16]},\n",
    "                    'anat_sequence':'t1_mprage', 'func_sequence':'SMS_mb3_3mm_TR1500',\n",
    "                    'date':'20190422', 'TR':1.5}\n",
    "# ... et cetera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,15,16,17,18,19,20,24,30,32,33,34,35,36,37,43,44,45,46,47,48,49,"
     ]
    }
   ],
   "source": [
    "for sub in dataset_params.keys():\n",
    "    print(sub, end=',')\n",
    "    with open('%s/%03d/dataset_params.json'%(nifti_dir,sub), 'w') as fp:\n",
    "        json.dump(dataset_params[sub], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_description = {\n",
    "    \"BIDSVersion\": \"1.1.1\",\n",
    "    \"Name\": \"YOUR_STUDY_NAME\",\n",
    "    \"Authors\": [\"YOU\", \"CO-AUTHOR 1\", \"CO-AUTHOR etc\"],\n",
    "    \"PhaseEncodingDirection\": \"j\", # Check this!\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset description json at /Volumes/jvanbaar/data/jvanbaar/polarization/sourcedata/dataset_description.json\n"
     ]
    }
   ],
   "source": [
    "dataset_description_path = dataset_dir + '/dataset_description.json'\n",
    "overwrite = True\n",
    "if os.path.isfile(dataset_description_path):\n",
    "    if overwrite:\n",
    "        print('Overwriting dataset description json at %s'%dataset_description_path)\n",
    "        with open(dataset_description_path, 'w') as outfile:  \n",
    "            json.dump(dataset_description, outfile)\n",
    "    else:\n",
    "        print('Dataset description json already exists at %s'%dataset_description_path)\n",
    "else:\n",
    "    with open(dataset_description_path, 'w') as outfile:  \n",
    "        json.dump(dataset_description, outfile)\n",
    "    print('Writing dataset description json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To BIDSify dataset per subject, see submit_BIDSify_jobs.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
